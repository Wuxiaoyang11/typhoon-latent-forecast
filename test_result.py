"""
æœ¬è„šæœ¬ç”¨äºåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å·²è®­ç»ƒå¥½çš„ LSTM æ¨¡å‹ï¼Œå¹¶ç”Ÿæˆé¢„æµ‹ç»“æœæŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨ã€‚
åŒ…å«è‡ªåŠ¨åå½’ä¸€åŒ– (Denormalization) åŠŸèƒ½ï¼Œå°†ç»“æœè¿˜åŸä¸º hPa å•ä½ã€‚
"""
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tqdm import tqdm

# é¡¹ç›®å†…éƒ¨å¼•ç”¨
from parse import parse_args
from lib.utils.dataloaders import get_dataloaders
from lib.models.lstm_predictor import LSTM

# =========================================================
# 1. å¼ºåŠ›è¡¥ä¸ï¼šå¼ºåˆ¶æŒ‡å®šé…ç½®æ–‡ä»¶ (è§£å†³ KeyError: None)
# =========================================================
# æ£€æŸ¥æ˜¯å¦ä¼ å…¥äº† config_fileï¼Œå¦‚æœæ²¡æœ‰ï¼Œå¼ºè¡ŒåŠ ä¸Š
has_config = False
for arg in sys.argv:
    if "--config_file" in arg:
        has_config = True
        break

if not has_config:
    print("âš ï¸ æœªæ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å‚æ•°ï¼Œæ­£åœ¨å¼ºåˆ¶åŠ è½½é»˜è®¤é…ç½®...")
    sys.argv.append("--config_file")
    # ç¡®ä¿è·¯å¾„æ­£ç¡®æŒ‡å‘ä½ çš„é…ç½®æ–‡ä»¶
    sys.argv.append("configs/train_lstm.conf")

# =========================================================
# 2. é…ç½®åŒºåŸŸ
# =========================================================
# ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒæŒ‡å‘ä½ ä»…å­˜çš„ checkpoint_1000.pth
CHECKPOINT_PATH = "models/ts/lstm_efficientnet/checkpoint_best.pth"
PLOT_SAVE_PATH = "result/prediction_result.png"

# === å½’ä¸€åŒ–å‚æ•° (åå½’ä¸€åŒ–ç”¨) ===
# ä½ çš„é¢„æµ‹å€¼åœ¨ -3 åˆ° 1 ä¹‹é—´ï¼Œè¯´æ˜æ˜¯ Z-Score æ ‡å‡†åŒ–ã€‚
# è¿™é‡Œä½¿ç”¨è¥¿å¤ªå¹³æ´‹å°é£æ°”å‹çš„ç»éªŒç»Ÿè®¡å€¼ã€‚
# å¦‚æœä½ çš„ dataset.py é‡Œæœ‰å‡†ç¡®çš„ mean/stdï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹ã€‚
NORM_MEAN = 965.0  # æ°”å‹å‡å€¼ (hPa)
NORM_STD = 20.0    # æ°”å‹æ ‡å‡†å·® (hPa)


def denormalize(data):
    """
    å°†æ¨¡å‹è¾“å‡ºçš„å½’ä¸€åŒ–æ•°å€¼è¿˜åŸä¸ºçœŸå®çš„ hPa æ°”å‹å€¼ã€‚
    å…¬å¼: Real = Norm * Std + Mean
    """
    return data * NORM_STD + NORM_MEAN


def setup_environment():
    args = parse_args()
    args.device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"æ­£åœ¨åŠ è½½é…ç½®: {args.config_file}")
    print(f"ä½¿ç”¨è®¾å¤‡: {args.device}")
    return args


def load_test_data(args):
    print("æ­£åœ¨åŠ è½½æµ‹è¯•é›†æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
    _, _, test_loader = get_dataloaders(args)
    print(f"æµ‹è¯•é›†åŒ…å« {len(test_loader.dataset)} ä¸ªåºåˆ—æ ·æœ¬ã€‚")
    return test_loader


def build_and_load_model(args, test_loader):
    print("æ­£åœ¨åˆå§‹åŒ– LSTM æ¨¡å‹...")
    # è‡ªåŠ¨è·å–è¾“å…¥è¾“å‡ºç»´åº¦
    input_size = test_loader.dataset.dataset.get_input_size()
    num_preds = test_loader.dataset.dataset.num_preds

    model = LSTM(
        input_size=input_size,
        hidden_size=args.hidden_dim, # 1024
        num_layers=args.num_layers,  # 3
        output_size=num_preds
    ).to(args.device)

    print(f"æ­£åœ¨åŠ è½½æƒé‡æ–‡ä»¶: {CHECKPOINT_PATH}")
    try:
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=args.device)
        # base.py ä¿å­˜æ—¶æŠŠå‚æ•°åŒ…åœ¨äº† 'model_dict' é”®é‡Œ
        model.load_state_dict(checkpoint['model_dict'])
        print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {CHECKPOINT_PATH}")
        print("è¯·ç¡®è®¤ lib/models/ts/lstm_efficientnet/ ä¸‹æ˜¯å¦å­˜åœ¨ checkpoint_1000.pth")
        return None

    model.eval()
    return model


def run_inference(model, dataloader, device):
    all_preds = []
    all_targets = []
    print("ğŸš€ å¼€å§‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†...")
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Testing"):
            inputs, targets = batch[0].to(device), batch[1].to(device)
            outputs = model(inputs)

            all_preds.append(outputs.cpu().numpy())
            all_targets.append(targets.cpu().numpy())

    # æ‹¼æ¥æ‰€æœ‰ Batch
    all_preds = np.concatenate(all_preds, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    return all_targets, all_preds


def report_metrics(targets, preds):
    """
    è®¡ç®—å¹¶æ‰“å°è¯„ä¼°æŒ‡æ ‡ (åå½’ä¸€åŒ–åçš„çœŸå® hPa)ã€‚
    """
    # 1. å½¢çŠ¶å¤„ç† (N, 4, 1) -> (N, 4)
    if targets.ndim == 3:
        targets = targets.squeeze(-1)
    if preds.ndim == 3:
        preds = preds.squeeze(-1)

    # 2. åå½’ä¸€åŒ– (è¿˜åŸä¸ºçœŸå®æ°”å‹)
    targets_hpa = denormalize(targets)
    preds_hpa = denormalize(preds)

    # 3. è®¡ç®—æ€»ä½“æŒ‡æ ‡
    mse = mean_squared_error(targets_hpa, preds_hpa)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(targets_hpa, preds_hpa)

    print("\n" + "=" * 40)
    print("       ğŸ‰ æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š (Test Set) ğŸ‰")
    print("=" * 40)
    print(f"RMSE (å‡æ–¹æ ¹è¯¯å·®): {rmse:.4f} hPa  <-- (è¶Šå°è¶Šå¥½)")
    print(f"MAE  (å¹³å‡ç»å¯¹è¯¯å·®): {mae:.4f} hPa")
    print("-" * 40)

    # 4. è®¡ç®—åˆ†æ­¥æŒ‡æ ‡ (Step-wise)
    num_steps = preds.shape[1]
    for i in range(num_steps):
        step_mse = mean_squared_error(targets_hpa[:, i], preds_hpa[:, i])
        step_rmse = np.sqrt(step_mse)
        print(f"Step {i+1} (æœªæ¥ {(i+1)*3}h): RMSE = {step_rmse:.4f} hPa")
    print("=" * 40)

    return targets_hpa, preds_hpa


def plot_results(targets, preds, save_path):
    print("æ­£åœ¨ç»˜åˆ¶é¢„æµ‹å¯¹æ¯”å›¾...")
    # åªå–å‰ 100 ä¸ªæ ·æœ¬ç”»å›¾
    subset_size = len(targets)

    # å¦‚æœæ˜¯å¤šæ­¥ï¼Œåªç”»ç¬¬1æ­¥ (æœªæ¥3å°æ—¶)
    if preds.ndim > 1:
        targets_plot = targets[:, 0]
        preds_plot = preds[:, 0]
    else:
        targets_plot = targets
        preds_plot = preds

    t = np.arange(subset_size)

    plt.figure(figsize=(12, 6), dpi=100)
    # çœŸå®å€¼ (çº¢å®çº¿)
    plt.plot(t, targets_plot[:subset_size], color='red', linestyle='-', linewidth=2, label='Ground Truth (Real)')
    # é¢„æµ‹å€¼ (è“è™šçº¿)
    plt.plot(t, preds_plot[:subset_size], color='blue', linestyle='--', linewidth=2, label='Prediction (LSTM)')

    plt.title('Typhoon Intensity Prediction (Central Pressure)', fontsize=16)
    plt.xlabel('Sample Index', fontsize=14)
    plt.ylabel('Pressure (hPa)', fontsize=14)
    plt.legend(fontsize=12, loc='best')
    plt.grid(True, alpha=0.3)

    plt.savefig(save_path, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜è‡³: {save_path}")
    print("è¯·åœ¨å·¦ä¾§æ–‡ä»¶åˆ—è¡¨åŒå‡»æ‰“å¼€è¯¥å›¾ç‰‡æŸ¥çœ‹ã€‚")


def main():
    args = setup_environment()
    test_loader = load_test_data(args)
    model = build_and_load_model(args, test_loader)

    if model is None:
        return

    # æ¨ç† -> æ‹¿åˆ°å½’ä¸€åŒ–çš„æ•°æ®
    raw_targets, raw_preds = run_inference(model, test_loader, args.device)

    # æŠ¥å‘Š -> å†…éƒ¨ä¼šè¿›è¡Œåå½’ä¸€åŒ–å¹¶æ‰“å°çœŸå® hPa è¯¯å·®
    real_targets, real_preds = report_metrics(raw_targets, raw_preds)

    # ç”»å›¾ -> ä½¿ç”¨åå½’ä¸€åŒ–åçš„æ•°æ®ç”»å›¾
    plot_results(real_targets, real_preds, PLOT_SAVE_PATH)


if __name__ == "__main__":
    main()